# Emma - Interfaz de Chat Inteligente para Ollama

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/version-rev_250718-green.svg)](https://github.com/ozkar-co/Emma)

Emma es una interfaz de chat inteligente en Python dise√±ada para interactuar con modelos de Ollama. Proporciona una experiencia de conversaci√≥n natural con capacidades avanzadas de an√°lisis de prompts, b√∫squeda inteligente y gesti√≥n de personalidades.

## üöÄ Caracter√≠sticas Principales

### ‚úÖ **Implementado y Funcional**
- **Chat Interactivo**: Interfaz de l√≠nea de comandos intuitiva
- **Arquitectura Modular**: Core refactorizado con adaptadores LLM y sistema de personalidades separado
- **Adapter Ollama**: Integraci√≥n completa con la API de Ollama
- **An√°lisis de Prompts**: Sistema inteligente que determina si una pregunta requiere b√∫squeda externa
- **Comandos de B√∫squeda**: Generaci√≥n autom√°tica de comandos `<search>`, `<memory>`, `<query>`
- **Sistema de Personalidades**: Archivos YAML separados para cada personalidad
- **Configuraci√≥n Flexible**: Archivo YAML para personalizaci√≥n completa
- **Gesti√≥n de Conversaciones**: Guardado autom√°tico de conversaciones

## üìã Tabla de Contenidos

- [Instalaci√≥n](#instalaci√≥n)
- [Uso R√°pido](#uso-r√°pido)
- [Configuraci√≥n](#configuraci√≥n)
- [Comandos Disponibles](#comandos-disponibles)
- [Personalidades](#personalidades)
- [Sistema de B√∫squeda](#sistema-de-b√∫squeda)
- [Contribuci√≥n](#contribuci√≥n)
- [Roadmap](#roadmap)
- [Changelog](#changelog)

## üõ†Ô∏è Instalaci√≥n

### Requisitos Previos
- Python 3.8 o superior
- Ollama instalado y configurado
- Modelo compatible en Ollama (ver recomendaciones abajo)

#### Modelos Recomendados

| Modelo | Tama√±o | Velocidad | Instrucciones | Personalidad | Recomendaci√≥n |
|--------|--------|-----------|---------------|--------------|---------------|
| llama3.2:3b | 3 GB | ‚ö°‚ö° | ‚úÖ Bueno | ‚úÖ Funciona bien | ‚≠ê RECOMENDADO |
| qwen2.5:7b | 4.7 GB | ‚ö° | ‚≠ê Excelente | ‚≠ê Excelente | ‚≠ê Mejor para herramientas |
| mistral:7b | 4.1 GB | ‚ö°‚ö° | ‚úÖ Bueno | ‚úÖ Funciona | ‚úÖ Buena opci√≥n |
| llama3.1:8b | 4.7 GB | ‚ö° | ‚úÖ Muy bueno | ‚úÖ Muy bueno | ‚úÖ M√°xima calidad |
| gemma3:1b | 815 MB | ‚ö°‚ö°‚ö° | ‚ùå Pobre | ‚ùå No funciona | ‚ùå NO recomendado |

**Nota**: Los modelos peque√±os (<3B par√°metros) tienen dificultades para mantener personalidades y seguir instrucciones complejas.

### Pasos de Instalaci√≥n

```bash
# 1. Clonar el repositorio
git clone https://github.com/ozkar-co/Emma.git
cd Emma

# 2. Crear entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Verificar que Ollama est√© ejecut√°ndose
ollama serve
```

## üöÄ Uso R√°pido

```bash
# Iniciar Emma (entra directamente en modo chat)
python emma.py

# Comandos disponibles en el chat:
# /help - Mostrar ayuda
# /personality list - Listar personalidades
# /personality set <nombre> - Cambiar personalidad
# /clear - Limpiar pantalla
# /exit - Salir
```

## ‚öôÔ∏è Configuraci√≥n

Emma se configura mediante el archivo `config.yaml`. Las opciones principales incluyen:

```yaml
# Configuraci√≥n del modelo
model: "gemma3:1b"
temperature: 0.7
max_tokens: 800

# Configuraci√≥n de la aplicaci√≥n
user_name: "Oz"
use_panels: false
ollama_host: "http://localhost:11434"

# Personalidades predefinidas
personalities:
  default: "Eres Emma, una asistente virtual inteligente y amigable."
  t√©cnica: "Eres Emma, una asistente t√©cnica experta en programaci√≥n..."
  creativa: "Eres Emma, una asistente creativa con gran imaginaci√≥n..."
```

## üéÆ Comandos Disponibles

### Comandos B√°sicos
- `/help` - Mostrar ayuda completa
- `/clear` - Limpiar la pantalla
- `/exit` - Salir de Emma

### Comandos de Personalidad
- `/personality list` - Listar personalidades disponibles
- `/personality set <nombre>` - Cambiar a una personalidad espec√≠fica
- `/personality info <nombre>` - Ver detalles de una personalidad

## üé≠ Personalidades

Emma incluye varias personalidades predefinidas:

| Personalidad | Descripci√≥n |
|--------------|-------------|
| `default` | Asistente amigable y vers√°til |
| `t√©cnica` | Especializada en programaci√≥n y tecnolog√≠a |
| `creativa` | Enfocada en ideas innovadoras |
| `concisa` | Respuestas breves y directas |
| `educativa` | Explicaciones claras y did√°cticas |
| `sexy` | Conversaciones de tem√°tica adulta |

## üîç Sistema de B√∫squeda

Emma analiza autom√°ticamente tus preguntas y determina si requieren informaci√≥n externa:

### Tipos de B√∫squeda
- **`<search>texto</search>`** - B√∫squedas en internet/Wikipedia
- **`<memory>texto</memory>`** - B√∫squedas en memoria interna
- **`<query>texto</query>`** - B√∫squedas en bases de datos/APIs

### Ejemplos
```
Usuario: "¬øCu√°l es la capital de Francia?"
Emma: "[Searching internet for: capital de Francia]"

Usuario: "¬øCu√°l fue mi √∫ltima conversaci√≥n sobre IA?"
Emma: "[Searching memory for: √∫ltima conversaci√≥n IA]"
```

## ü§ù Contribuci√≥n

¬°Las contribuciones son bienvenidas! Aqu√≠ est√°n los pasos fundamentales para contribuir:

### Proceso de Contribuci√≥n

1. **Fork del proyecto** y clona tu repositorio
2. **Implementa tu feature** o mejora
3. **Actualiza la documentaci√≥n**:
   - Si es una nueva caracter√≠stica importante, mu√©vela del Roadmap a la lista de Features
   - Actualiza el README.md seg√∫n corresponda
4. **Actualiza el Changelog** con los detalles de tus cambios
5. **Si usaste una nueva librer√≠a**, a√±√°dela a la secci√≥n de Agradecimientos
6. **Crea un Pull Request** con una descripci√≥n clara

### Notas Importantes

- Mant√©n el c√≥digo simple y legible
- Sigue las convenciones de nomenclatura existentes
- Documenta cualquier nueva funcionalidad
- Los cambios deben ser compatibles con la configuraci√≥n actual

## üó∫Ô∏è Roadmap

### üéØ **Ruta Principal** - Contribuciones al Core

#### **Arquitectura Modular** ‚úÖ **COMPLETADO**
- **Refactorizaci√≥n del Core**: Arquitectura modular para mejor mantenibilidad ‚úÖ
- **Adapter LLM Base**: Interfaz base y adaptadores para Ollama ‚úÖ
- **System Prompts Separados**: Archivos individuales para cada personalidad ‚úÖ

#### **Interfaz y Memoria**
- **STT/TTS B√°sico**: Comandos de voz iniciales (Speech-to-Text / Text-to-Speech)
- **Memoria Contextual**: Sistema b√°sico de memoria contextual
- **Memoria Avanzada**: Base de datos local con embeddings locales
- **Consulta por Relevancia**: B√∫squeda en memoria previa por similitud

### üî¨ **Ruta Alternativa** - Experimentos e Ideas

#### **Expansi√≥n de Capacidades**
- **Motor LLM Din√°mico**: Selecci√≥n din√°mica entre local/remoto
- **Medici√≥n de Tokens**: Estimaci√≥n de tokens por interacci√≥n
- **GUI Gr√°fica**: Interfaz gr√°fica de usuario
- **Plugin de Emociones**: Avatar visual con expresiones basadas en el mood

#### **Integraciones Futuras**
- **B√∫squedas en Internet**: APIs de b√∫squeda/Wikipedia
- **B√∫squedas en Base de Datos**: Conexiones con APIs personalizadas
- **Sistema de Plugins**: Arquitectura para funcionalidades adicionales
- **API REST**: Endpoints para integraci√≥n externa
- **Docker Support**: Containerizaci√≥n de la aplicaci√≥n

## üìù Changelog

Para ver el historial completo de cambios, consulta el archivo [CHANGELOG.md](CHANGELOG.md).

### Versi√≥n Actual: rev_250718
- **Refactorizaci√≥n completa del Core**: Arquitectura modular implementada
- **Adapter Ollama**: Integraci√≥n completa y modular con la API de Ollama
- **Sistema de Personalidades Separado**: Archivos YAML individuales para cada personalidad
- **Mejoras en la Configuraci√≥n**: Sistema de configuraci√≥n m√°s limpio y modular
- Sistema de versionado por fechas
- Documentaci√≥n completamente renovada
- Roadmap detallado con ruta principal y alternativa

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## üôè Agradecimientos

- [Ollama](https://ollama.ai/) por proporcionar la infraestructura de modelos
- [Rich](https://rich.readthedocs.io/) por la interfaz de terminal
- [Typer](https://typer.tiangolo.com/) por el framework CLI
- [Pydantic](https://pydantic-docs.helpmanual.io/) por la validaci√≥n de datos

---

**¬øNecesitas ayuda?** Abre un [issue](https://github.com/ozkar-co/Emma/issues) o consulta la [documentaci√≥n](docs/). 