# Configuración para Emma - Refactored for Modular Architecture
# ===========================================================

# Configuración del modelo
model: "gemma3:1b"
temperature: 0.7
max_tokens: 800        # Reducido para evitar problemas con modelos más pequeños
top_p: 0.9
top_k: 40
context_size: 2048     # Reducido para evitar problemas con modelos más pequeños

# Configuración de la conversación
system_prompt: ""      # Ahora se maneja a través de archivos de personalidad
chat_history_limit: 10  # Reducido para evitar exceder el contexto máximo
save_conversations: true
conversation_dir: "conversations"

# Configuración de la aplicación
verbose: false
ollama_host: "http://localhost:11434"
api_key: "AAAAC3NzaC1lZDI1NTE5AAAAICXiy0gtY2IoK/1I0i5YV/stWE7U8+5tGaFXBG6IxuAw"
user_name: "Oz"  # Nombre del usuario para mostrar en el chat en lugar de "Tú"
use_panels: false  # Mostrar mensajes de Emma sin panel/recuadro

# Configuración de personalidades
personalities_dir: "personalities"  # Directorio donde se almacenan los archivos de personalidad